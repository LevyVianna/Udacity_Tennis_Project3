{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1 - Install the necessary packages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip -q install ./python"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2 - Importing the necessary packages\n",
    "\n",
    "\n",
    "We begin by importing some necessary packages.  If the code cell below returns an error, please revisit the project instructions to double-check that you have installed [Unity ML-Agents](https://github.com/Unity-Technologies/ml-agents/blob/master/docs/Installation.md) and [NumPy](http://www.numpy.org/)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from unityagents import UnityEnvironment\n",
    "import numpy as np\n",
    "from collections import deque\n",
    "import torch\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "\n",
    "from agent import *"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3 - Starting the Unity environment\n",
    "\n",
    "**_Before running the code cell below_**, change the `file_name` parameter to match the location of the Unity environment that you downloaded.\n",
    "\n",
    "- **Mac**: `\"path/to/Tennis.app\"`\n",
    "- **Windows** (x86): `\"path/to/Tennis_Windows_x86/Tennis.exe\"`\n",
    "- **Windows** (x86_64): `\"path/to/Tennis_Windows_x86_64/Tennis.exe\"`\n",
    "- **Linux** (x86): `\"path/to/Tennis_Linux/Tennis.x86\"`\n",
    "- **Linux** (x86_64): `\"path/to/Tennis_Linux/Tennis.x86_64\"`\n",
    "- **Linux** (x86, headless): `\"path/to/Tennis_Linux_NoVis/Tennis.x86\"`\n",
    "- **Linux** (x86_64, headless): `\"path/to/Tennis_Linux_NoVis/Tennis.x86_64\"`\n",
    "\n",
    "For instance, if you are using a Mac, then you downloaded `Tennis.app`.  If this file is in the same folder as the notebook, then the line below should appear as follows:\n",
    "```\n",
    "env = UnityEnvironment(file_name=\"Tennis.app\")\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:unityagents:\n",
      "'Academy' started successfully!\n",
      "Unity Academy name: Academy\n",
      "        Number of Brains: 1\n",
      "        Number of External Brains : 1\n",
      "        Lesson number : 0\n",
      "        Reset Parameters :\n",
      "\t\t\n",
      "Unity brain name: TennisBrain\n",
      "        Number of Visual Observations (per agent): 0\n",
      "        Vector Observation space type: continuous\n",
      "        Vector Observation space size (per agent): 8\n",
      "        Number of stacked Vector Observation: 3\n",
      "        Vector Action space type: continuous\n",
      "        Vector Action space size (per agent): 2\n",
      "        Vector Action descriptions: , \n"
     ]
    }
   ],
   "source": [
    "env = UnityEnvironment(file_name=\"C:\\\\Users\\\\levy0\\\\Documents\\\\Udacity\\\\projects\\\\Tennis_Windows_x86_64\\\\Tennis.exe\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "  ### 4 - Getting some information of the state and action spaces"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of agents: 2\n",
      "Size of each action: 2\n",
      "There are 2 agents. Each observes a state with length: 24\n",
      "The state for the first agent looks like: [ 0.          0.          0.          0.          0.          0.\n",
      "  0.          0.          0.          0.          0.          0.\n",
      "  0.          0.          0.          0.         -6.65278625 -1.5\n",
      " -0.          0.          6.83172083  6.         -0.          0.        ]\n"
     ]
    }
   ],
   "source": [
    "# get the default brain\n",
    "brain_name = env.brain_names[0]\n",
    "brain = env.brains[brain_name]\n",
    "\n",
    "# reset the environment\n",
    "env_info = env.reset(train_mode=True)[brain_name]\n",
    "\n",
    "# number of agents \n",
    "num_agents = len(env_info.agents)\n",
    "print('Number of agents:', num_agents)\n",
    "\n",
    "# size of each action\n",
    "action_size = brain.vector_action_space_size\n",
    "print('Size of each action:', action_size)\n",
    "\n",
    "# examine the state space \n",
    "states = env_info.vector_observations\n",
    "state_size = states.shape[1]\n",
    "print('There are {} agents. Each observes a state with length: {}'.format(states.shape[0], state_size))\n",
    "print('The state for the first agent looks like:', states[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 5 - The DDPG trainning function\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def ddpg_trainning():\n",
    "    \n",
    "    num_agents = 2\n",
    "    id_agents = np.arange(num_agents)\n",
    "    \n",
    "    env_info = env.reset(train_mode=True)[brain_name]\n",
    "    state_size = env_info.vector_observations.shape[1]\n",
    "    \n",
    "    action_size = brain.vector_action_space_size\n",
    "    \n",
    "    agent_1 = Agent(state_size,action_size,0)\n",
    "    agent_2 = Agent(state_size,action_size,1)\n",
    "    \n",
    "    scores = []\n",
    "    scores_window = deque(maxlen=100)\n",
    "    solved = False\n",
    "    \n",
    "    theta=0.15 \n",
    "    sigma=0.20\n",
    "    NOISE_DECAY = 1.0 #0.9999\n",
    "    \n",
    "    for i_episode in range(5000):\n",
    "\n",
    "        env_info = env.reset(train_mode=True)[brain_name]\n",
    "        states = env_info.vector_observations\n",
    "        score = np.zeros(2)\n",
    "        theta *= NOISE_DECAY\n",
    "        sigma *= NOISE_DECAY\n",
    "        \n",
    "        \n",
    "        for i in range(1000):\n",
    "            \n",
    "            actions = np.zeros([num_agents, action_size])\n",
    "            actions[0, :] = agent_1.act(states[0], True, theta, sigma)\n",
    "            actions[1, :] = agent_2.act(states[1], True, theta, sigma)\n",
    "\n",
    "            env_info = env.step(actions)[brain_name]\n",
    "            next_states = env_info.vector_observations\n",
    "            rewards = env_info.rewards\n",
    "            dones = env_info.local_done\n",
    "            \n",
    "            agent_1.step(states, actions, rewards[0], next_states, dones[0])\n",
    "            agent_2.step(states, actions, rewards[1], next_states, dones[1])\n",
    "            \n",
    "            score += rewards\n",
    "            states = next_states\n",
    "            if np.any(dones):\n",
    "                break\n",
    "                \n",
    "        scores.append(np.max(score))\n",
    "        scores_window.append(np.max(score))\n",
    "        if i_episode % 200 == 0:\n",
    "            print('\\rEpisode {}\\tAverage Score: {:.3f}'.format(i_episode, np.mean(scores_window)))\n",
    "        if np.mean(scores_window) >= 0.5:\n",
    "            solved = True\n",
    "            episode_solved = i_episode-100\n",
    "            torch.save(agent_1.actor_local.state_dict(), \"a_1-a.pth\")\n",
    "            torch.save(agent_1.critic_local.state_dict(), \"a_1-c.pth\")\n",
    "            torch.save(agent_2.actor_local.state_dict(), \"a_2-a.pth\")\n",
    "            torch.save(agent_2.critic_local.state_dict(), \"a_2-c.pth\")\n",
    "            \n",
    "            break\n",
    "    if solved:\n",
    "        print('\\nEnvironment solved in {:d} episodes!'.format(episode_solved))\n",
    "    else:\n",
    "        print(\"Environment not solved\")\n",
    "        \n",
    "    return scores"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 6 - Trainning and solving"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Episode 0\tAverage Score: 0.000\n",
      "Episode 200\tAverage Score: 0.001\n",
      "Episode 400\tAverage Score: 0.001\n",
      "Episode 600\tAverage Score: 0.000\n",
      "Episode 800\tAverage Score: 0.000\n",
      "Episode 1000\tAverage Score: 0.004\n",
      "Episode 1200\tAverage Score: 0.017\n",
      "Episode 1400\tAverage Score: 0.003\n",
      "Episode 1600\tAverage Score: 0.001\n",
      "Episode 1800\tAverage Score: 0.002\n",
      "Episode 2000\tAverage Score: 0.014\n",
      "Episode 2200\tAverage Score: 0.025\n",
      "Episode 2400\tAverage Score: 0.057\n",
      "Episode 2600\tAverage Score: 0.083\n",
      "Episode 2800\tAverage Score: 0.099\n",
      "Episode 3000\tAverage Score: 0.133\n",
      "Episode 3200\tAverage Score: 0.197\n",
      "Episode 3400\tAverage Score: 0.490\n",
      "\n",
      "Environment solved in 3301 episodes!\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "scores = ddpg_trainning()\n",
    "\n",
    "# plot the scores\n",
    "fig = plt.figure()\n",
    "ax = fig.add_subplot(111)\n",
    "plt.plot(np.arange(len(scores)), scores)\n",
    "plt.ylabel('Score')\n",
    "plt.xlabel('Episode #')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 7 - Closing the environment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "env.close()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
